{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e862fc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch as torch\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import math\n",
    "from torch.utils.data import Dataset\n",
    "import itertools\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import gzip\n",
    "import numpy as np\n",
    "import random\n",
    "import scipy\n",
    "from collections import defaultdict\n",
    "from scipy.spatial import distance\n",
    "import dateutil\n",
    "import os\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import json, time\n",
    "import pandas as pd\n",
    "def parseData(fname):\n",
    "    for l in open(fname):\n",
    "        yield eval(l)\n",
    "        \n",
    "def readDataFull(path):\n",
    "    data = []\n",
    "    for line in gzip.open(path):\n",
    "        d = eval(line)\n",
    "        data.append(d)  \n",
    "    return data\n",
    "\n",
    "def readData_full(path):\n",
    "    data = []\n",
    "    for line in open(path):\n",
    "        d = json.loads(line)\n",
    "        data.append(d)  \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f0daaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFolder = 'data/ca/'\n",
    "users_file_name = dataFolder + 'ca_users.json'\n",
    "places_file_name = dataFolder + 'ca_places.json'\n",
    "reviews_file_name = dataFolder + 'ca_final_reviews.json'\n",
    "\n",
    "data_user  = pd.DataFrame(readData_full(users_file_name))\n",
    "data_places  = pd.DataFrame(readData_full(places_file_name))\n",
    "data_reviews  = pd.DataFrame(readData_full(reviews_file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29e0edd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>categories</th>\n",
       "      <th>gPlusPlaceId</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>gPlusUserId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>william spindler</td>\n",
       "      <td>Best War Wanton soup in Red Bluff</td>\n",
       "      <td>[Asian Restaurant, Chinese Restaurant]</td>\n",
       "      <td>106591714648856494903</td>\n",
       "      <td>1.394669e+09</td>\n",
       "      <td>Mar 12, 2014</td>\n",
       "      <td>100000032416892623125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>william spindler</td>\n",
       "      <td>This is a review that is long overdo. I've bee...</td>\n",
       "      <td>[European Restaurant, Italian Restaurant, Pizz...</td>\n",
       "      <td>109420033090810328045</td>\n",
       "      <td>1.394826e+09</td>\n",
       "      <td>Mar 14, 2014</td>\n",
       "      <td>100000032416892623125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>william spindler</td>\n",
       "      <td>Some authentic rub BBQ, great food and don't m...</td>\n",
       "      <td>[Barbecue Restaurant]</td>\n",
       "      <td>111623070919810985923</td>\n",
       "      <td>1.394671e+09</td>\n",
       "      <td>Mar 12, 2014</td>\n",
       "      <td>100000032416892623125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>william spindler</td>\n",
       "      <td>Truly a Red Bluff standard. Great old fashione...</td>\n",
       "      <td>[Restaurant]</td>\n",
       "      <td>113854191152597312098</td>\n",
       "      <td>1.394670e+09</td>\n",
       "      <td>Mar 12, 2014</td>\n",
       "      <td>100000032416892623125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>william spindler</td>\n",
       "      <td>Long time favorite Mexican food, always consis...</td>\n",
       "      <td>[Mexican Restaurant]</td>\n",
       "      <td>115827996910815192564</td>\n",
       "      <td>1.394670e+09</td>\n",
       "      <td>Mar 12, 2014</td>\n",
       "      <td>100000032416892623125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285084</th>\n",
       "      <td>2.0</td>\n",
       "      <td>charles mckinney</td>\n",
       "      <td>Too many gangs frequent this place.</td>\n",
       "      <td>[Flea Market]</td>\n",
       "      <td>116649125736549598195</td>\n",
       "      <td>1.367212e+09</td>\n",
       "      <td>Apr 28, 2013</td>\n",
       "      <td>118446742455312620560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285085</th>\n",
       "      <td>2.0</td>\n",
       "      <td>charles mckinney</td>\n",
       "      <td>None</td>\n",
       "      <td>[Mexican Restaurant, Latin American Restaurant]</td>\n",
       "      <td>117332598175065149705</td>\n",
       "      <td>1.368435e+09</td>\n",
       "      <td>May 13, 2013</td>\n",
       "      <td>118446742455312620560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285086</th>\n",
       "      <td>4.0</td>\n",
       "      <td>charles mckinney</td>\n",
       "      <td>None</td>\n",
       "      <td>[Hot Dog Restaurant, Takeout Restaurant, Fast ...</td>\n",
       "      <td>117868066122653879601</td>\n",
       "      <td>1.317842e+09</td>\n",
       "      <td>Oct 5, 2011</td>\n",
       "      <td>118446742455312620560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285087</th>\n",
       "      <td>1.0</td>\n",
       "      <td>charles mckinney</td>\n",
       "      <td>i will never go back. food and customer servic...</td>\n",
       "      <td>[Buffet Restaurant, American Restaurant]</td>\n",
       "      <td>117952004983617019485</td>\n",
       "      <td>1.315602e+09</td>\n",
       "      <td>Sep 9, 2011</td>\n",
       "      <td>118446742455312620560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285088</th>\n",
       "      <td>1.0</td>\n",
       "      <td>charles mckinney</td>\n",
       "      <td>None</td>\n",
       "      <td>[Mexican Restaurant, Latin American Restaurant]</td>\n",
       "      <td>118224418815687780032</td>\n",
       "      <td>1.315603e+09</td>\n",
       "      <td>Sep 9, 2011</td>\n",
       "      <td>118446742455312620560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>285089 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        rating      reviewerName  \\\n",
       "0          4.0  william spindler   \n",
       "1          5.0  william spindler   \n",
       "2          5.0  william spindler   \n",
       "3          4.0  william spindler   \n",
       "4          5.0  william spindler   \n",
       "...        ...               ...   \n",
       "285084     2.0  charles mckinney   \n",
       "285085     2.0  charles mckinney   \n",
       "285086     4.0  charles mckinney   \n",
       "285087     1.0  charles mckinney   \n",
       "285088     1.0  charles mckinney   \n",
       "\n",
       "                                               reviewText  \\\n",
       "0                       Best War Wanton soup in Red Bluff   \n",
       "1       This is a review that is long overdo. I've bee...   \n",
       "2       Some authentic rub BBQ, great food and don't m...   \n",
       "3       Truly a Red Bluff standard. Great old fashione...   \n",
       "4       Long time favorite Mexican food, always consis...   \n",
       "...                                                   ...   \n",
       "285084                Too many gangs frequent this place.   \n",
       "285085                                               None   \n",
       "285086                                               None   \n",
       "285087  i will never go back. food and customer servic...   \n",
       "285088                                               None   \n",
       "\n",
       "                                               categories  \\\n",
       "0                  [Asian Restaurant, Chinese Restaurant]   \n",
       "1       [European Restaurant, Italian Restaurant, Pizz...   \n",
       "2                                   [Barbecue Restaurant]   \n",
       "3                                            [Restaurant]   \n",
       "4                                    [Mexican Restaurant]   \n",
       "...                                                   ...   \n",
       "285084                                      [Flea Market]   \n",
       "285085    [Mexican Restaurant, Latin American Restaurant]   \n",
       "285086  [Hot Dog Restaurant, Takeout Restaurant, Fast ...   \n",
       "285087           [Buffet Restaurant, American Restaurant]   \n",
       "285088    [Mexican Restaurant, Latin American Restaurant]   \n",
       "\n",
       "                 gPlusPlaceId  unixReviewTime    reviewTime  \\\n",
       "0       106591714648856494903    1.394669e+09  Mar 12, 2014   \n",
       "1       109420033090810328045    1.394826e+09  Mar 14, 2014   \n",
       "2       111623070919810985923    1.394671e+09  Mar 12, 2014   \n",
       "3       113854191152597312098    1.394670e+09  Mar 12, 2014   \n",
       "4       115827996910815192564    1.394670e+09  Mar 12, 2014   \n",
       "...                       ...             ...           ...   \n",
       "285084  116649125736549598195    1.367212e+09  Apr 28, 2013   \n",
       "285085  117332598175065149705    1.368435e+09  May 13, 2013   \n",
       "285086  117868066122653879601    1.317842e+09   Oct 5, 2011   \n",
       "285087  117952004983617019485    1.315602e+09   Sep 9, 2011   \n",
       "285088  118224418815687780032    1.315603e+09   Sep 9, 2011   \n",
       "\n",
       "                  gPlusUserId  \n",
       "0       100000032416892623125  \n",
       "1       100000032416892623125  \n",
       "2       100000032416892623125  \n",
       "3       100000032416892623125  \n",
       "4       100000032416892623125  \n",
       "...                       ...  \n",
       "285084  118446742455312620560  \n",
       "285085  118446742455312620560  \n",
       "285086  118446742455312620560  \n",
       "285087  118446742455312620560  \n",
       "285088  118446742455312620560  \n",
       "\n",
       "[285089 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2943e7",
   "metadata": {},
   "source": [
    "### Construct data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01426c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "st0Min, st0Max = 32.534, 42.009\n",
    "st1Min, st1Max = -124.4, -114.13\n",
    "bk = 200\n",
    "bin0 = np.linspace(st0Min, st0Max, bk)\n",
    "bin0 = [(a, b) for a, b in zip(bin0[:-1], bin0[1:])]\n",
    "bin1 = np.linspace(st1Min, st1Max, bk)\n",
    "bin1 = [(a, b) for a, b in zip(bin1[:-1], bin1[1:])]\n",
    "\n",
    "def getBin(gps0, gps1):\n",
    "    b0, b1 = 0, 0\n",
    "    for i, (a, b) in enumerate(bin0):\n",
    "        if gps0 >= a and gps0 < b:\n",
    "            b0 = i\n",
    "    for i, (a, b) in enumerate(bin1):\n",
    "        if gps1 >= a and gps1 < b:\n",
    "            b1 = i\n",
    "    return bk * b0 + b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6b681bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "placesDict = {}\n",
    "for i, p in data_places.iterrows():\n",
    "    placesDict[p['gPlusPlaceId']] = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6dfc747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.33063829787234\n"
     ]
    }
   ],
   "source": [
    "userIDs = {}\n",
    "itemIDs = {}\n",
    "categoryIDs = {}\n",
    "\n",
    "interactions = []\n",
    "interactionsPerUser = defaultdict(list)\n",
    "userVisitedPlaces = defaultdict(set)\n",
    "uniquePlaces = set()\n",
    "for _i, d in data_reviews.iterrows():\n",
    "    u = d['gPlusUserId']\n",
    "    i = d['gPlusPlaceId']\n",
    "    t = d['unixReviewTime']\n",
    "    r = d['rating']\n",
    "    cat = str(d['categories'])\n",
    "    gps = placesDict[d['gPlusPlaceId']]['gps']\n",
    "    b = getBin(gps[0], gps[1])\n",
    "    \n",
    "    uniquePlaces.add(i)\n",
    "    #dt = dateutil.parser.parse(t)\n",
    "    #t = int(dt.timestamp())\n",
    "    if not u in userIDs: userIDs[u] = len(userIDs)\n",
    "    if not i in itemIDs: itemIDs[i] = len(itemIDs)\n",
    "    if not cat in categoryIDs: categoryIDs[cat] = len(categoryIDs)\n",
    "    interactions.append((t,u,i,r,b,cat))\n",
    "    interactionsPerUser[u].append((t,i,r,b,cat))\n",
    "    userVisitedPlaces[u].add(i)\n",
    "    \n",
    "interactions.sort()\n",
    "userInteractionAvg = sum ([len(interactionsPerUser[u]) for u in interactionsPerUser])  / len(interactionsPerUser)\n",
    "print(userInteractionAvg)\n",
    "\n",
    "itemIDs['dummy'] = len(itemIDs)\n",
    "\n",
    "\n",
    "interactionstrain = []\n",
    "interactionstest = []\n",
    "for u in interactionsPerUser:\n",
    "    interactionsPerUser[u].sort()\n",
    "    list_users = interactionsPerUser[u]\n",
    "    lastItem = 'dummy'\n",
    "    lastB = 0\n",
    "    \n",
    "    for (t,i,r,b,cat) in list_users[:-1]:\n",
    "        interactionstrain.append((u,i,lastItem,b,lastB,cat))\n",
    "        lastItem = i\n",
    "        lastB = b\n",
    "\n",
    "    (t,i,r,b,cat) = list_users[-1]\n",
    "    interactionstest.append((u,i,lastItem,b,lastB,cat))\n",
    "    lastItem = i\n",
    "    lastB = b\n",
    "\n",
    "itemsPerUser = defaultdict(set)\n",
    "for u,i,j,b,pb,cat in interactionstrain:\n",
    "    itemsPerUser[u].add(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cede231c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16450 62003 15254\n",
      "268639\n",
      "16450\n"
     ]
    }
   ],
   "source": [
    "nUsers,nItems,nCat = len(userIDs),len(itemIDs),len(categoryIDs)\n",
    "items = list(itemIDs.keys())\n",
    "print(nUsers,nItems,nCat)\n",
    "print(len(interactionstrain))\n",
    "print(len(interactionstest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "feb9aa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = ['userId_index', 'placeId_index', 'lastplaceId_index', 'bin', 'prev_bin', 'cat']\n",
    "features_sizes = {\n",
    "    'userId_index': nUsers,\n",
    "    'placeId_index':nItems,\n",
    "    'lastplaceId_index':nItems,\n",
    "    'bin': bk * bk,\n",
    "    'prev_bin': bk * bk,\n",
    "    'cat': nCat\n",
    "}\n",
    "\n",
    "next_offset = 0\n",
    "features_offsets={}\n",
    "index = 0\n",
    "for k,v in features_sizes.items():\n",
    "    features_offsets[index] = next_offset\n",
    "    index += 1\n",
    "    next_offset += v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f9dd6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "x_train_neg = []\n",
    "\n",
    "def feat(x):\n",
    "    return [x[i] + features_offsets[i] for i in range(len(x))]\n",
    "\n",
    "for (u,i,j,b,pb,cat) in interactionstrain:\n",
    "    uindex = userIDs[u]\n",
    "    iindex = itemIDs[i]\n",
    "    jindex = itemIDs[j]\n",
    "    cat_index = categoryIDs[cat]\n",
    "    x_train.append(feat((uindex, iindex, jindex, b, pb, cat_index)))\n",
    "    \n",
    "    k = random.choice(items) # negative sample\n",
    "    while k in itemsPerUser[u]:\n",
    "        k = random.choice(items)\n",
    "    uindex = userIDs[u]\n",
    "    kindex = itemIDs[k]\n",
    "    jindex = itemIDs[j] \n",
    "    gps = (st0Min, st1Min) if k == 'dummy' else placesDict[k]['gps']\n",
    "    negB = getBin(gps[0], gps[1])\n",
    "    x_train_neg.append(feat((uindex, kindex, jindex, negB, pb, cat_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2594763e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = torch.tensor(x_train)\n",
    "data_x_neg = torch.tensor(x_train_neg)\n",
    "dataset = data.TensorDataset(data_x,data_x_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "677b7884",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=100000\n",
    "train_n = int(len(dataset)*0.8)\n",
    "valid_n = len(dataset) - train_n\n",
    "splits = [train_n,valid_n]\n",
    "assert sum(splits) == len(dataset)\n",
    "trainset,devset = torch.utils.data.random_split(dataset,splits)\n",
    "train_dataloader = data.DataLoader(trainset,batch_size=bs,shuffle=True)\n",
    "dev_dataloader = data.DataLoader(devset,batch_size=bs,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53dd3390",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trunc_normal_(x, mean=0., std=1.):\n",
    "    \"Truncated normal initialization.\"\n",
    "    return x.normal_().fmod_(2).mul_(std).add_(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2f7d989",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FMModel(nn.Module):\n",
    "    def __init__(self, n, k):\n",
    "        super().__init__()\n",
    "\n",
    "        self.w0 = nn.Parameter(torch.zeros(1))\n",
    "        self.bias = nn.Embedding(n, 1)\n",
    "        self.embeddings = nn.Embedding(n, k)\n",
    "\n",
    "        with torch.no_grad(): trunc_normal_(self.embeddings.weight, std=0.01)\n",
    "        with torch.no_grad(): trunc_normal_(self.bias.weight, std=0.01)\n",
    "\n",
    "    def forward(self, X_pos, X_neg):\n",
    "        emb = self.embeddings(X_pos)\n",
    "        pow_of_sum = emb.sum(dim=1).pow(2)\n",
    "        sum_of_pow = emb.pow(2).sum(dim=1)\n",
    "        pairwise = (pow_of_sum-sum_of_pow).sum(1)*0.5\n",
    "        bias = self.bias(X_pos).squeeze().sum(1)\n",
    "        \n",
    "        pos = self.w0 + bias + pairwise\n",
    "        \n",
    "        emb = self.embeddings(X_neg)\n",
    "        pow_of_sum = emb.sum(dim=1).pow(2)\n",
    "        sum_of_pow = emb.pow(2).sum(dim=1)\n",
    "        pairwise = (pow_of_sum-sum_of_pow).sum(1)*0.5\n",
    "        bias = self.bias(X_neg).squeeze().sum(1)        \n",
    "        \n",
    "        neg = self.w0 + bias + pairwise\n",
    "        loss = -torch.mean(torch.log(torch.sigmoid(pos - neg)))\n",
    "        return loss\n",
    "    \n",
    "    def predict_1(self, X):\n",
    "        \n",
    "        emb = self.embeddings(X)\n",
    "        pow_of_sum = emb.sum(dim=1).pow(2)\n",
    "        sum_of_pow = emb.pow(2).sum(dim=1)\n",
    "        pairwise = (pow_of_sum-sum_of_pow).sum(1)*0.5\n",
    "        bias = self.bias(X).sum(1)\n",
    "        \n",
    "        return self.w0 + bias + pairwise \n",
    "    def predict_2(self, X):\n",
    "        \n",
    "        emb = self.embeddings(X)\n",
    "        pow_of_sum = emb.sum(dim=1).pow(2)\n",
    "        sum_of_pow = emb.pow(2).sum(dim=1)\n",
    "        pairwise = (pow_of_sum-sum_of_pow).sum(1)*0.5\n",
    "        bias = self.bias(X).squeeze().sum(1) \n",
    "        \n",
    "        return self.w0 + bias + pairwise \n",
    "        #return pos - neg\n",
    "    \n",
    "        #return torch.mean(torch.log(torch.sigmoid(pos - neg)))\n",
    "    \n",
    "        #return -tf.reduce_mean(tf.math.log(tf.math.sigmoid(x_uij - x_ukj)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7561c1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(iterator, model, optimizer, criterion):\n",
    "    train_loss = 0\n",
    "    model.train()\n",
    "    for x_pos,x_neg in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        loss = model(x_pos, x_neg)\n",
    "        train_loss += loss.item()*x_pos.shape[0]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return train_loss / len(iterator.dataset)\n",
    "\n",
    "def test(iterator, model, criterion):\n",
    "    train_loss = 0\n",
    "    model.eval()\n",
    "    for x_pos,x_neg in iterator:                    \n",
    "        with torch.no_grad():\n",
    "            loss = model(x_pos, x_neg)\n",
    "        train_loss += loss.item()*x_pos.shape[0]\n",
    "    return train_loss / len(iterator.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2813fd17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0. time: 15[s]\n",
      "\ttrain loss: 0.6725\n",
      "\tvalidation loss: 0.5522\n",
      "epoch 1. time: 74[s]\n",
      "\ttrain loss: 0.4680\n",
      "\tvalidation loss: 0.3817\n",
      "epoch 2. time: 5[s]\n",
      "\ttrain loss: 0.2535\n",
      "\tvalidation loss: 0.3029\n",
      "epoch 3. time: 7[s]\n",
      "\ttrain loss: 0.1370\n",
      "\tvalidation loss: 0.2710\n",
      "epoch 4. time: 7[s]\n",
      "\ttrain loss: 0.0798\n",
      "\tvalidation loss: 0.2611\n",
      "epoch 5. time: 4[s]\n",
      "\ttrain loss: 0.0533\n",
      "\tvalidation loss: 0.2602\n",
      "epoch 6. time: 8[s]\n",
      "\ttrain loss: 0.0426\n",
      "\tvalidation loss: 0.2623\n",
      "epoch 7. time: 7[s]\n",
      "\ttrain loss: 0.0401\n",
      "\tvalidation loss: 0.2640\n",
      "epoch 8. time: 4[s]\n",
      "\ttrain loss: 0.0402\n",
      "\tvalidation loss: 0.2648\n",
      "epoch 9. time: 8[s]\n",
      "\ttrain loss: 0.0406\n",
      "\tvalidation loss: 0.2651\n",
      "epoch 10. time: 11[s]\n",
      "\ttrain loss: 0.0390\n",
      "\tvalidation loss: 0.2649\n",
      "epoch 11. time: 4[s]\n",
      "\ttrain loss: 0.0386\n",
      "\tvalidation loss: 0.2643\n",
      "epoch 12. time: 7[s]\n",
      "\ttrain loss: 0.0379\n",
      "\tvalidation loss: 0.2635\n",
      "epoch 13. time: 6[s]\n",
      "\ttrain loss: 0.0371\n",
      "\tvalidation loss: 0.2626\n",
      "epoch 14. time: 10[s]\n",
      "\ttrain loss: 0.0363\n",
      "\tvalidation loss: 0.2617\n",
      "epoch 15. time: 9[s]\n",
      "\ttrain loss: 0.0356\n",
      "\tvalidation loss: 0.2608\n",
      "epoch 16. time: 5[s]\n",
      "\ttrain loss: 0.0350\n",
      "\tvalidation loss: 0.2600\n",
      "epoch 17. time: 10[s]\n",
      "\ttrain loss: 0.0345\n",
      "\tvalidation loss: 0.2592\n",
      "epoch 18. time: 9[s]\n",
      "\ttrain loss: 0.0342\n",
      "\tvalidation loss: 0.2586\n",
      "epoch 19. time: 5[s]\n",
      "\ttrain loss: 0.0340\n",
      "\tvalidation loss: 0.2580\n",
      "epoch 20. time: 9[s]\n",
      "\ttrain loss: 0.0339\n",
      "\tvalidation loss: 0.2575\n",
      "epoch 21. time: 10[s]\n",
      "\ttrain loss: 0.0338\n",
      "\tvalidation loss: 0.2571\n",
      "epoch 22. time: 5[s]\n",
      "\ttrain loss: 0.0339\n",
      "\tvalidation loss: 0.2567\n",
      "epoch 23. time: 11[s]\n",
      "\ttrain loss: 0.0340\n",
      "\tvalidation loss: 0.2563\n",
      "epoch 24. time: 6[s]\n",
      "\ttrain loss: 0.0341\n",
      "\tvalidation loss: 0.2560\n",
      "epoch 25. time: 9[s]\n",
      "\ttrain loss: 0.0342\n",
      "\tvalidation loss: 0.2556\n",
      "epoch 26. time: 11[s]\n",
      "\ttrain loss: 0.0344\n",
      "\tvalidation loss: 0.2553\n",
      "epoch 27. time: 6[s]\n",
      "\ttrain loss: 0.0345\n",
      "\tvalidation loss: 0.2551\n",
      "epoch 28. time: 8[s]\n",
      "\ttrain loss: 0.0346\n",
      "\tvalidation loss: 0.2548\n",
      "epoch 29. time: 7[s]\n",
      "\ttrain loss: 0.0348\n",
      "\tvalidation loss: 0.2545\n",
      "epoch 30. time: 4[s]\n",
      "\ttrain loss: 0.0349\n",
      "\tvalidation loss: 0.2543\n",
      "epoch 31. time: 9[s]\n",
      "\ttrain loss: 0.0349\n",
      "\tvalidation loss: 0.2540\n",
      "epoch 32. time: 6[s]\n",
      "\ttrain loss: 0.0350\n",
      "\tvalidation loss: 0.2538\n",
      "epoch 33. time: 10[s]\n",
      "\ttrain loss: 0.0350\n",
      "\tvalidation loss: 0.2537\n",
      "epoch 34. time: 11[s]\n",
      "\ttrain loss: 0.0351\n",
      "\tvalidation loss: 0.2535\n",
      "epoch 35. time: 5[s]\n",
      "\ttrain loss: 0.0351\n",
      "\tvalidation loss: 0.2533\n",
      "epoch 36. time: 9[s]\n",
      "\ttrain loss: 0.0351\n",
      "\tvalidation loss: 0.2532\n",
      "epoch 37. time: 4[s]\n",
      "\ttrain loss: 0.0351\n",
      "\tvalidation loss: 0.2530\n",
      "epoch 38. time: 8[s]\n",
      "\ttrain loss: 0.0350\n",
      "\tvalidation loss: 0.2529\n",
      "epoch 39. time: 9[s]\n",
      "\ttrain loss: 0.0350\n",
      "\tvalidation loss: 0.2528\n",
      "epoch 40. time: 5[s]\n",
      "\ttrain loss: 0.0350\n",
      "\tvalidation loss: 0.2527\n",
      "epoch 41. time: 9[s]\n",
      "\ttrain loss: 0.0349\n",
      "\tvalidation loss: 0.2527\n",
      "epoch 42. time: 9[s]\n",
      "\ttrain loss: 0.0348\n",
      "\tvalidation loss: 0.2526\n",
      "epoch 43. time: 6[s]\n",
      "\ttrain loss: 0.0348\n",
      "\tvalidation loss: 0.2525\n",
      "epoch 44. time: 10[s]\n",
      "\ttrain loss: 0.0347\n",
      "\tvalidation loss: 0.2524\n",
      "epoch 45. time: 8[s]\n",
      "\ttrain loss: 0.0346\n",
      "\tvalidation loss: 0.2524\n",
      "epoch 46. time: 5[s]\n",
      "\ttrain loss: 0.0345\n",
      "\tvalidation loss: 0.2523\n",
      "epoch 47. time: 9[s]\n",
      "\ttrain loss: 0.0344\n",
      "\tvalidation loss: 0.2523\n",
      "epoch 48. time: 6[s]\n",
      "\ttrain loss: 0.0343\n",
      "\tvalidation loss: 0.2522\n",
      "epoch 49. time: 9[s]\n",
      "\ttrain loss: 0.0342\n",
      "\tvalidation loss: 0.2521\n"
     ]
    }
   ],
   "source": [
    "model = FMModel(data_x.max()+1, 10)\n",
    "wd=1e-5\n",
    "lr=0.05\n",
    "epochs=50\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10], gamma=0.1)\n",
    "criterion = nn.MSELoss()\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    train_loss = fit(train_dataloader, model, optimizer, criterion)\n",
    "    valid_loss = test(dev_dataloader, model, criterion)\n",
    "    scheduler.step()\n",
    "    secs = int(time.time() - start_time)\n",
    "    print(f'epoch {epoch}. time: {secs}[s]')\n",
    "    print(f'\\ttrain loss: {((train_loss)):.4f}')\n",
    "    print(f'\\tvalidation loss: {((valid_loss)):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36a462b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8398400000000109"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactionsTestPerUser = defaultdict(set)\n",
    "itemSet = set()\n",
    "for u,i,j,b,pb,cat in interactionstest:\n",
    "    interactionsTestPerUser[u].add((i,j,b,pb,cat))\n",
    "    itemSet.add(i)\n",
    "    itemSet.add(j)\n",
    "    \n",
    "def AUCu(model, u, N):\n",
    "    win = 0\n",
    "    positive = [random.sample(interactionsTestPerUser[u],1)[0]] * N\n",
    "    negative = random.sample(itemSet,N)\n",
    "    for (i,j,b,pb,cat),k in zip(positive,negative):\n",
    "        pos1 = np.array([feat((userIDs[u], itemIDs[i], itemIDs[j], b, pb, categoryIDs[cat]))])\n",
    "        gps = placesDict[k]['gps']\n",
    "        negB = getBin(gps[0], gps[1])\n",
    "        neg1 = np.array([feat((userIDs[u], itemIDs[k], itemIDs[j], negB, pb, categoryIDs[cat]))])\n",
    "        p1 =  torch.LongTensor(pos1)\n",
    "        n1 =  torch.LongTensor(neg1)\n",
    "        sp = model.predict_1(p1).item()\n",
    "        sn = model.predict_1(n1).item()\n",
    "        #sp = model.predict(userIDs[u], itemIDs[i], itemIDs[j])\n",
    "        #sn = model.predict(userIDs[u], itemIDs[k], itemIDs[j])\n",
    "        if sp > sn:\n",
    "            win += 1\n",
    "    return win/N\n",
    "\n",
    "def AUC(model):\n",
    "    av = []\n",
    "    cnt = 0\n",
    "    for u in interactionsTestPerUser:\n",
    "        if cnt % 5000 == 0:\n",
    "            print(cnt)\n",
    "        cnt += 1\n",
    "        if cnt > 5000:\n",
    "            break\n",
    "        av.append(AUCu(model, u, 10))\n",
    "    return sum(av) / len(av)\n",
    "AUC(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0647d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1249439",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
